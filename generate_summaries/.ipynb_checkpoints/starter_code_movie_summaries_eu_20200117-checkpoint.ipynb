{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses ths guide: https://stackabuse.com/text-summarization-with-nltk-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll need all these packages. You might need to install the extra nltk packages (see: https://www.nltk.org/data.html)\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading txt as pandas\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/ezgiulusoy/Downloads/MovieSummaries/plot_summaries.csv', names = [\"ID\", \"summary\"])\n",
    "df.columns = df.columns.str.strip()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be better. Instead of defining string text, it needs to import the .txt file to pandas\n",
    "# Where each row is a new movie summary\n",
    "\n",
    "## article_text = '''\n",
    "## In 1936, archaeologist Indiana Jones braves an ancient Peruvian temple filled with booby traps to retrieve a golden idol. Upon fleeing the temple, Indiana is confronted by rival archaeologist René Belloq and the indigenous Hovitos. Surrounded and outnumbered, Indiana is forced to surrender the idol to Belloq and escapes aboard a waiting Waco seaplane, in the process revealing his fear of snakes. Shortly after returning to the college in the United States where he teaches archaeology, Indiana is interviewed by two Army intelligence agents. They inform him that the Nazis, in their quest for occult power, are searching for his old mentor, Abner Ravenwood, who is the leading expert on the ancient Egyptian city of Tanis and possesses the headpiece of an artifact called the Staff of Ra. Indiana deduces that the Nazis are searching for Tanis because it is believed to be the location of the Ark of the Covenant, the biblical chest built by the Israelites to contain the fragments of the Ten Commandments; the Nazis believe that if they acquire it, their armies will become invincible. The Staff of Ra, meanwhile, is the key to finding the Well of Souls, a secret chamber in which the Ark is buried. The agents subsequently authorize Indiana to recover the Ark before the Nazis. Indiana travels to Nepal, only to find that Ravenwood has died and that the headpiece is in the possession of his daughter, Marion, Indiana's embittered former lover. Indiana offers to buy the headpiece for three thousand dollars, plus two thousand more when they return to the United States. Marion's tavern is suddenly raided by a group of thugs commanded by Nazi agent Toht. The tavern is burned down in the ensuing fight, during which Toht burns his hand on the searing hot headpiece as he tries to grab it. Indiana and Marion escape with the headpiece, with Marion declaring she will accompany Indiana in his search for the Ark so he can repay his debt. They travel to Cairo where they learn from Indiana's friend Sallah, a skilled excavator, that Belloq and the Nazis, led by Colonel Dietrich, are currently digging for the Well of Souls with a replica of the headpiece modeled after the scar on Toht's hand. In a bazaar, Nazi operatives attempt to kidnap Marion and as Indiana chases after them it appears that she dies in an explosion. While deciphering the markings on the headpiece, Indiana and Sallah realize that the Nazis have miscalculated the location of the Well of Souls. Using this to their advantage, they infiltrate the Nazi dig and use the Staff of Ra to determine the location correctly and uncover the Well of Souls, which is filled with snakes. Indiana fends off the snakes and acquires the Ark, but Belloq, Dietrich and the Nazis arrive to take it. They toss Marion into the well with Indiana and seal them in, but they manage to escape. After a fistfight with a giant Nazi mechanic, blowing up a flying wing on the airstrip, and chasing down a convoy of trucks, Indiana takes back the Ark before it can be shipped to Berlin. Indiana and Marion leave Cairo to escort the Ark to England on board a tramp steamer. The next morning, their boat is boarded by Belloq, Dietrich and the Nazis, who once again steal the Ark and kidnap Marion. Indiana stows away on their U-boat and follows them to an isolated island in the Aegean Sea where Belloq plans to test the power of the Ark before presenting it to Hitler. Indiana reveals himself and threatens to destroy the Ark with a rocket-propelled grenade launcher, but Belloq calls his bluff, knowing Indy cannot bear to eradicate an important historical artifact. Indiana surrenders and is tied to a post with Marion as Belloq performs a ceremonial opening of the Ark, which appears to contain nothing but sand. Suddenly, spirits resembling Old Testament Seraphim emerge from the Ark. Aware of the supernatural danger of looking at the opened Ark, Indiana warns Marion to close her eyes. The apparitions suddenly morph into \"angels of death\", and lightning bolts begin flying out of the Ark, gruesomely killing the Nazi soldiers, while Belloq, Dietrich and Toht meet even more gruesome fates. The fires rise into the sky, then fall back down to Earth and the Ark closes with a crack of thunder. Back in Washington, D.C., the Army intelligence agents tell a suspicious Indiana and Brody that the Ark \"is someplace safe\" to be studied by \"top men\". In reality, the Ark is sealed in a wooden crate labeled \"top secret\" and stored in a giant government warehouse filled with countless similar crates.\n",
    "## '''\n",
    "\n",
    "##Ezgi: We do not need this section anymore. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Square Brackets and Extra Spaces\n",
    "## article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
    "## article_text = re.sub(r'\\s+', ' ', article_text)\n",
    "\n",
    "##Ezgi's add --> I changed the name article_text to article_text_clear to make it obvious\n",
    "\n",
    "size = len(df.summary)\n",
    "article_text_clear = [\"\" for x in range(size)]\n",
    "for i in range(size):\n",
    "    article_text_clear[i] = re.sub(r'\\[[0-9]*\\]', ' ', df.summary[i])\n",
    "    article_text_clear[i] = re.sub(r'\\s+', ' ', df.summary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing special characters and digits\n",
    "## formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
    "## formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)\n",
    "\n",
    "##Ezgi's add (I'm sorry if name changes are confusing. Since I named article_text as _clear --> I added _cl at the end of formatted_article as well)\n",
    "\n",
    "formatted_article_text_cl = [\"\" for x in range(size)]\n",
    "for i in range(size):\n",
    "    formatted_article_text_cl[i] = re.sub('[^a-zA-Z]', ' ', article_text_clear[i] )\n",
    "    formatted_article_text_cl[i] = re.sub(r'\\s+', ' ', formatted_article_text_cl[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Text to Sentences \n",
    "\n",
    "##Ezgi's add\n",
    "\n",
    "sentence_list = [\"\" for x in range(size)]\n",
    "for i in range(size):\n",
    "    sentence_list[i] = nltk.sent_tokenize(article_text_clear[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Weighted Frequency of Occurance\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "## word_frequencies = {}\n",
    "## for word in nltk.word_tokenize(formatted_article_text):\n",
    " ##   if word not in stopwords:\n",
    "  ##      if word not in word_frequencies.keys():\n",
    "   ##         word_frequencies[word] = 1\n",
    "    ##    else:\n",
    "     ##       word_frequencies[word] += 1\n",
    "        \n",
    "        ##Ezgi's add \n",
    "#I found  13145138 by word counting the summaries with =IF(LEN(TRIM(A2))=0,0,LEN(TRIM(A2))-LEN(SUBSTITUTE(A2,\" \",\"\"))+1)\n",
    "#and then create a data set with word count from each line. Opened it on stata, and summarize values --> r(sum). \n",
    "#I am sure they is easier way to get the total word count. That was the easiest for me.)\n",
    "\n",
    "word_frequencies = {}\n",
    "word = [\"\" for x in range (0, 13145138)]\n",
    "for x in range (0, 13145138):\n",
    "    for word[i] in nltk.word_tokenize(formatted_article_text_cl[i]):\n",
    "        if word[i] not in stopwords:\n",
    "            if word[i] not in word_frequencies.keys():\n",
    "                word_frequencies[word[i]] = 1\n",
    "            else:\n",
    "                word_frequencies[word[i]] += 1 \n",
    "                \n",
    "##I tried this code with a smaller range and it worked. But it is taking years in my computer to run this. \n",
    "#Is it the code? or is it my computer? \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Weighted Frequency\n",
    "## maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "## for word in word_frequencies.keys():\n",
    " ##   word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "    \n",
    "    ##Ezgi's add\n",
    "    \n",
    "maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "for word[i] in word_frequencies.keys():\n",
    "    word_frequencies[word[i]] = (word_frequencies[word[i]]/maximum_frequncy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Sentence Scores\n",
    "## sentence_scores = {}\n",
    "## for sent in sentence_list:\n",
    "  ##   for word in nltk.word_tokenize(sent.lower()):\n",
    "   ##      if word in word_frequencies.keys():\n",
    "     ##        if len(sent.split(' ')) < 20: ## Change this to specify how long/short of sentences you want to include\n",
    "     ##            if sent not in sentence_scores.keys():\n",
    "     ##                sentence_scores[sent] = word_frequencies[word]\n",
    "       ##          else:\n",
    "       ##              sentence_scores[sent] += word_frequencies[word]\n",
    "                    \n",
    "##Ezgi's add \n",
    "sentence_scores = {}\n",
    "sent = [\"\" for x in range(size)]\n",
    "for i in range(size):\n",
    "    for sent[i] in sentence_list[i]:\n",
    "        for word[i] in nltk.word_tokenize(sent[i].lower()):\n",
    "            if word[i] in word_frequencies.keys():\n",
    "                if len(sent[i].split(' ')) < 20: ## Change this to specify how long/short of sentences you want to include\n",
    "                    if sent[i] not in sentence_scores.keys():\n",
    "                        sentence_scores[sent[i]] = word_frequencies[word[i]]\n",
    "                    else:\n",
    "                        sentence_scores[sent[i]] += word_frequencies[word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marion's tavern is suddenly raided by a group of thugs commanded by Nazi agent Toht. Upon fleeing the temple, Indiana is confronted by rival archaeologist René Belloq and the indigenous Hovitos.\n"
     ]
    }
   ],
   "source": [
    "# Get a Summary\n",
    "# This needs to be better. Instead of summarizing the text defined above, this should be a for loop that\n",
    "# Runs a text summary on every row in the pandas data frame defined above\n",
    "\n",
    "##Ezgi: I have stopped here!\n",
    "\n",
    "import heapq\n",
    "#Change value here to get summary sentence length\n",
    "summary_sentences = heapq.nlargest(2, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "summary = ' '.join(summary_sentences)\n",
    "print(summary)\n",
    "\n",
    "##I tried this but it did not work: \n",
    "# summary_sentences_looped = [\"\" for x in range(size)]\n",
    "# for i in range(size):\n",
    " #   summary_sentences_looped[i] = heapq.nlargest(2, sentence_scores[i], key=sentence_scores[i].get)\n",
    "\n",
    "# summary = ' '.join(summary_sentences_looped[i])\n",
    "# print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, now it is time to score the summaries on arousal, valence, and dominance. There is a nice dictionary by\n",
    "# Bradley and Lang that will let you do exactly that. You can borrow that here:\n",
    "# https://github.com/dwzhou/SentimentAnalysis\n",
    "\n",
    "# Biasically, you'll want to classify each cell in the Pandas Dataframe (where each cell contains a movie summary)\n",
    "# along arousal, valence, and dominance. So we can get a score for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this is super optional and likely not necissary. You could, instead of using a dictionary approach,\n",
    "# Train a classifier to do your sentiment analysis. This would be cooler, but also probably a lot of work\n",
    "# And I'm not sure it would gain us all that much. But if you are feeling energetic, or the Lang dictionary\n",
    "# doesn't work, here is some hints about training a classifier.\n",
    "\n",
    "#Train a text sentiment classifier. Here we are in good shape because most are trained on movie ratings\n",
    "# But you could also train the classifier on the un summarized movie reviews\n",
    "# For ideas on how to do this, check out: https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
